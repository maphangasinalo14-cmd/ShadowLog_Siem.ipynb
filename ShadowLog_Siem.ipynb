{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maphangasinalo14-cmd/ShadowLog_Siem.ipynb/blob/main/ShadowLog_Siem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXDJ995iznHH",
        "outputId": "0d9992d1-afd0-4029-dc62-6d4a8c770eb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Installing dependencies (this may take 1 minute)...\n",
            "‚úÖ Dependencies installed\n",
            "üìù Writing application files...\n",
            "‚úÖ Files created\n",
            "üöÄ Starting Streamlit...\n",
            "‚úÖ Streamlit is running in background.\n",
            "\n",
            "============================================================\n",
            "‚úÖ SHADOWLOG IS LIVE: https://uninvestigable-roxane-scablike.ngrok-free.dev\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =====================================================================\n",
        "# SHADOWLOG - DEBUG MODE (VERBOSE)\n",
        "# =====================================================================\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "import signal\n",
        "import atexit\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "class ShadowLogLauncher:\n",
        "    def __init__(self):\n",
        "        self.process: Optional[subprocess.Popen] = None\n",
        "\n",
        "    def install_dependencies(self):\n",
        "        print(\"üîß Installing dependencies (this may take 1 minute)...\")\n",
        "        # CHANGED: Removed output suppression so you can see it working\n",
        "        packages = [\"pandas\", \"plotly\", \"streamlit\", \"scikit-learn\", \"faker\", \"numpy\", \"pyngrok\"]\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + packages)\n",
        "            print(\"‚úÖ Dependencies installed\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"‚ùå Installation failed: {e}\")\n",
        "            sys.exit(1)\n",
        "\n",
        "    def write_files(self):\n",
        "        print(\"üìù Writing application files...\")\n",
        "\n",
        "        # 1. LOG GENERATOR\n",
        "        log_gen = '''import random, json\n",
        "from datetime import datetime, timedelta\n",
        "from faker import Faker\n",
        "from pathlib import Path\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "ATTACKS = {\n",
        "    \"sql\": [\"/api?id=1' OR '1'='1\", \"/login?u=admin'--\", \"/q?sql=UNION SELECT\"],\n",
        "    \"xss\": [\"/msg?t=<script>alert(1)</script>\", \"/bio?v=<img src=x onerror=alert(1)>\"],\n",
        "    \"path\": [\"/file?p=../../etc/passwd\", \"/view?f=../../../root/.ssh/id_rsa\"],\n",
        "    \"brute\": [\"/admin/login\", \"/wp-login.php\", \"/ssh\"]\n",
        "}\n",
        "\n",
        "NORMAL = [\"/\", \"/home\", \"/about\", \"/api/data\", \"/img/logo.png\", \"/products\"]\n",
        "\n",
        "def generate_logs(n=5000):\n",
        "    logs, attackers = [], set()\n",
        "\n",
        "    # Normal traffic\n",
        "    for _ in range(int(n*0.70)):\n",
        "        ip, ts = fake.ipv4(), fake.date_time_between('-2d').strftime('%d/%b/%Y:%H:%M:%S +0000')\n",
        "        path, status = random.choice(NORMAL), random.choice([200,200,200,404])\n",
        "        logs.append(f'{ip} - - [{ts}] \"GET {path} HTTP/1.1\" {status} {random.randint(300,5000)} \"-\" \"Mozilla/5.0\"')\n",
        "\n",
        "    # Brute Force\n",
        "    attacker = f\"203.0.113.55\"\n",
        "    attackers.add(attacker)\n",
        "    base = datetime.now()-timedelta(hours=2)\n",
        "    for i in range(500):\n",
        "        ts = (base+timedelta(seconds=i)).strftime('%d/%b/%Y:%H:%M:%S +0000')\n",
        "        logs.append(f'{attacker} - - [{ts}] \"POST {random.choice(ATTACKS[\"brute\"])} HTTP/1.1\" 401 120 \"-\" \"Mozilla/5.0\"')\n",
        "\n",
        "    # SQL Injection\n",
        "    for i in range(5):\n",
        "        ip = f\"198.51.100.{100+i}\"\n",
        "        attackers.add(ip)\n",
        "        for _ in range(50):\n",
        "            ts = fake.date_time_between('-2d').strftime('%d/%b/%Y:%H:%M:%S +0000')\n",
        "            logs.append(f'{ip} - - [{ts}] \"GET {random.choice(ATTACKS[\"sql\"])} HTTP/1.1\" 200 450 \"-\" \"sqlmap/1.5\"')\n",
        "\n",
        "    random.shuffle(logs)\n",
        "    Path(\"server_access.log\").write_text(\"\\\\n\".join(logs))\n",
        "    json.dump({\"total\": len(logs), \"attack_ips\": list(attackers)}, open(\"metadata.json\", \"w\"))\n",
        "    print(f\"‚úÖ Generated {len(logs)} logs\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_logs()\n",
        "'''\n",
        "\n",
        "        # 2. ANALYZER\n",
        "        analyzer = '''import re, pandas as pd, numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class LogAnalyzer:\n",
        "    PATTERN = re.compile(r'(?P<ip>\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+) - - \\\\[(?P<ts>.*?)\\\\] \"(?P<method>\\\\w+) (?P<path>.*?) HTTP/1\\\\.1\" (?P<status>\\\\d+) (?P<size>\\\\d+)')\n",
        "\n",
        "    def __init__(self, file=\"server_access.log\"):\n",
        "        self.file = file\n",
        "\n",
        "    def parse(self):\n",
        "        data = []\n",
        "        with open(self.file) as f:\n",
        "            for line in f:\n",
        "                m = self.PATTERN.search(line)\n",
        "                if m: data.append(m.groupdict())\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "        df['status'] = pd.to_numeric(df['status'])\n",
        "        df['size'] = pd.to_numeric(df['size'])\n",
        "        df['ts'] = pd.to_datetime(df['ts'], format='%d/%b/%Y:%H:%M:%S %z')\n",
        "\n",
        "        df['sql_inj'] = df['path'].str.contains(r\"(?i)(union|select|drop|'|--)\", regex=True)\n",
        "        df['xss'] = df['path'].str.contains(r\"(?i)(<script|onerror|alert)\", regex=True)\n",
        "        df['path_trav'] = df['path'].str.contains(r\"\\\\.\\\\./\", regex=True)\n",
        "        df['has_attack'] = df['sql_inj'] | df['xss'] | df['path_trav']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def analyze(self):\n",
        "        raw = self.parse()\n",
        "        features = raw.groupby('ip').agg(\n",
        "            requests=('path','count'),\n",
        "            unique_paths=('path','nunique'),\n",
        "            error_rate=('status', lambda x: (x>=400).mean()),\n",
        "            avg_size=('size','mean'),\n",
        "            req_per_min=('ts', lambda x: len(x)/max(1,(x.max()-x.min()).total_seconds()/60)),\n",
        "            has_sig=('has_attack', 'any')\n",
        "        ).reset_index().fillna(0)\n",
        "\n",
        "        X = features[['requests','unique_paths','error_rate','avg_size','req_per_min']].values\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        model = IsolationForest(contamination=0.15, random_state=42)\n",
        "        features['ml_anomaly'] = model.fit_predict(X_scaled)\n",
        "        features['is_threat'] = (features['ml_anomaly']==-1) | (features['has_sig']==True)\n",
        "\n",
        "        def level(r):\n",
        "            if not r['is_threat']: return 'NORMAL'\n",
        "            if r['has_sig']: return 'CRITICAL'\n",
        "            if r['error_rate']>0.7 and r['requests']>100: return 'CRITICAL'\n",
        "            if r['req_per_min']>5: return 'HIGH'\n",
        "            return 'MEDIUM'\n",
        "\n",
        "        features['threat_level'] = features.apply(level, axis=1)\n",
        "        return raw, features\n",
        "\n",
        "def analyze_logs():\n",
        "    return LogAnalyzer().analyze()\n",
        "'''\n",
        "\n",
        "        # 3. DASHBOARD\n",
        "        dashboard = '''import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import os, json\n",
        "from log_gen import generate_logs\n",
        "from analyzer import analyze_logs\n",
        "\n",
        "st.set_page_config(page_title=\"ShadowLog SIEM\", page_icon=\"üïµÔ∏è\", layout=\"wide\")\n",
        "\n",
        "st.markdown(\"\"\"<style>\n",
        "div[data-testid=\"stMetric\"] {border: 1px solid #444; padding: 10px; border-radius: 5px;}\n",
        "</style>\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.title(\"üïµÔ∏è ShadowLog SIEM\")\n",
        "st.divider()\n",
        "\n",
        "with st.sidebar:\n",
        "    size = st.selectbox(\"Log Size\", [1000,3000,5000], index=1)\n",
        "    if st.button(\"üîÑ Generate Logs\"):\n",
        "        generate_logs(size)\n",
        "        st.cache_data.clear()\n",
        "        st.rerun()\n",
        "    threat_filter = st.multiselect(\"Filter\", [\"CRITICAL\",\"HIGH\",\"MEDIUM\"], [\"CRITICAL\",\"HIGH\"])\n",
        "    min_req = st.slider(\"Min Requests\", 0, 500, 1)\n",
        "\n",
        "if not os.path.exists(\"server_access.log\"):\n",
        "    generate_logs(3000)\n",
        "\n",
        "@st.cache_data(ttl=300)\n",
        "def load_data():\n",
        "    return analyze_logs()\n",
        "\n",
        "with st.spinner(\"Analyzing...\"):\n",
        "    raw, threats = load_data()\n",
        "\n",
        "c1,c2,c3 = st.columns(3)\n",
        "c1.metric(\"Total Events\", len(raw))\n",
        "c2.metric(\"Threats\", len(threats[threats['is_threat']]))\n",
        "c3.metric(\"Critical\", len(threats[threats['threat_level']=='CRITICAL']))\n",
        "\n",
        "st.divider()\n",
        "filtered = threats[\n",
        "    (threats['threat_level'].isin(threat_filter)) &\n",
        "    (threats['requests'] >= min_req) &\n",
        "    (threats['is_threat'])\n",
        "].sort_values('requests', ascending=False)\n",
        "\n",
        "if filtered.empty:\n",
        "    st.info(\"No threats found\")\n",
        "else:\n",
        "    for _, row in filtered.iterrows():\n",
        "        with st.expander(f\"üî¥ {row['threat_level']} - {row['ip']}\"):\n",
        "            st.write(f\"Error Rate: {row['error_rate']:.1%}\")\n",
        "            st.code(raw[raw['ip']==row['ip']]['path'].head(5).tolist())\n",
        "'''\n",
        "\n",
        "        Path(\"log_gen.py\").write_text(log_gen)\n",
        "        Path(\"analyzer.py\").write_text(analyzer)\n",
        "        Path(\"app.py\").write_text(dashboard)\n",
        "        print(\"‚úÖ Files created\")\n",
        "\n",
        "    def run(self):\n",
        "        atexit.register(lambda: self.process.kill() if self.process else None)\n",
        "\n",
        "        self.install_dependencies()\n",
        "        self.write_files()\n",
        "\n",
        "        print(\"üöÄ Starting Streamlit...\")\n",
        "        from pyngrok import ngrok\n",
        "        ngrok.kill()\n",
        "\n",
        "        # Start Streamlit\n",
        "        self.process = subprocess.Popen(\n",
        "            [sys.executable, \"-m\", \"streamlit\", \"run\", \"app.py\",\n",
        "             \"--server.headless=true\", \"--server.port=8501\",\n",
        "             \"--browser.gatherUsageStats=false\"],\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE # Capture errors\n",
        "        )\n",
        "\n",
        "        # DEBUG CHECK: Wait 5 seconds and see if it crashed\n",
        "        time.sleep(5)\n",
        "        if self.process.poll() is not None:\n",
        "            print(\"\\n‚ùå STREAMLIT CRASHED IMMEDIATELY!\")\n",
        "            print(\"Error logs:\")\n",
        "            print(self.process.stderr.read().decode())\n",
        "            return\n",
        "\n",
        "        print(\"‚úÖ Streamlit is running in background.\")\n",
        "\n",
        "        # Start Ngrok\n",
        "        try:\n",
        "            public_url = ngrok.connect(8501).public_url\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(f\"‚úÖ SHADOWLOG IS LIVE: {public_url}\")\n",
        "            print(\"=\"*60)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Ngrok Error: {e}\")\n",
        "            print(\"Note: If you didn't add an Auth Token, Ngrok might limit your connections.\")\n",
        "\n",
        "        # Keep alive\n",
        "        try:\n",
        "            while True: time.sleep(1)\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"Stopped.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ShadowLogLauncher().run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsP9EJMwdJNeTG/1C0yLh6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}